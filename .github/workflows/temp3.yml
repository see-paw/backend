name: CI - Tests And Inspection

on:
  pull_request:
    branches: [ "develop" ]
    paths-ignore:
       - '.github/workflows/**'

# Adicionar permissÃµes para comentar nos PRs
permissions:
  contents: read
  pull-requests: write
  issues: write

env:
  DOTNET_VERSION: "8.0.x"
  ASPNETCORE_ENVIRONMENT: "Test"

jobs:
  # ======================================================
  # 1ï¸âƒ£ BUILD JOB
  # ======================================================
  build:
    runs-on: ubuntu-latest
    container:
      image: mcr.microsoft.com/dotnet/sdk:8.0

    steps:
      - name: Checkout cÃ³digo
        uses: actions/checkout@v4

      - name: Cache do NuGet
        uses: actions/cache@v4
        with:
          path: ~/.nuget/packages
          key: ${{ runner.os }}-nuget-${{ hashFiles('**/*.csproj') }}
          restore-keys: |
            ${{ runner.os }}-nuget-

      - name: Restaurar dependÃªncias
        run: dotnet restore SeePaw.sln

      - name: Compilar projeto
        run: dotnet build SeePaw.sln --no-restore --configuration Release

      - name: Guardar artefactos do build
        uses: actions/upload-artifact@v4
        with:
          name: build-artifacts
          path: |
            **/bin/Release/
            **/obj/Release/

  # ======================================================
  # 2ï¸âƒ£ UNIT TESTS
  # ======================================================
  unit_tests:
    runs-on: ubuntu-latest
    container:
      image: mcr.microsoft.com/dotnet/sdk:8.0
    needs: build

    steps:
      - name: Checkout cÃ³digo
        uses: actions/checkout@v4
        
      # NÃƒO descarregar artefactos - vamos recompilar tudo
      # Isto resolve problemas de referÃªncias entre projetos
          
      - name: Restaurar dependÃªncias
        run: dotnet restore SeePaw.sln

      - name: Compilar soluÃ§Ã£o completa
        run: dotnet build SeePaw.sln --no-restore --configuration Release

      - name: Instalar ferramenta de cobertura
        run: dotnet add Tests/Tests.csproj package coverlet.collector
        
      - name: Correr testes unitÃ¡rios (xUnit) + Cobertura
        run: |
         mkdir -p TestResults

          echo "ğŸ§ª A testar: Tests/Tests.csproj"
          
          dotnet test Tests/Tests.csproj \
            --no-restore \
            --configuration Release \
            --logger "trx;LogFileName=test-results.trx" \
            --results-directory TestResults \
            --collect:"XPlat Code Coverage" \
            -- DataCollectionRunSettings.DataCollectors.DataCollector.Configuration.Format=opencover
          
          echo ""
          echo "âœ… Testes concluÃ­dos"
          echo ""
          
          coverage_file=$(find TestResults -name "coverage.*.xml" -type f | head -1)

          if [ -n "$coverage_file" ]; then
            cp "$coverage_file" TestResults/coverage.xml
            echo "âœ… Cobertura encontrada: $coverage_file"
            
            # Mostrar que formato foi encontrado
            if [[ "$coverage_file" == *"opencover"* ]]; then
              echo "ğŸ“Š Formato: OpenCover"
            elif [[ "$coverage_file" == *"cobertura"* ]]; then
              echo "ğŸ“Š Formato: Cobertura"
            fi
          else
            echo "âš ï¸ Nenhum ficheiro de cobertura encontrado"
          fi
            
          
          echo ""
          echo "ğŸ“‚ Ficheiros finais em TestResults:"
          ls -lah TestResults/
          echo ""
          echo "ğŸ“‚ Estrutura completa:"
          find TestResults -type f
            
      - name: Mostrar resumo dos testes
        if: always()
        run: |
          if [ -f TestResults/test-results.trx ]; then
            echo "âœ… Testes executados com sucesso"
            
            passed=$(grep -o 'outcome="Passed"' TestResults/test-results.trx | wc -l || echo "0")
            failed=$(grep -o 'outcome="Failed"' TestResults/test-results.trx | wc -l || echo "0")
            total=$((passed + failed))
            
            echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“"
            echo "ğŸ“Š RESUMO DOS TESTES UNITÃRIOS"
            echo "â”£â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”«"
            echo "   Total: $total"
            echo "   âœ… Passaram: $passed"
            echo "   âŒ Falharam: $failed"
            
            if [ $failed -eq 0 ] && [ $total -gt 0 ]; then
              echo "   ğŸ‰ Todos os testes passaram!"
            elif [ $failed -gt 0 ]; then
              echo "   âš ï¸  Alguns testes falharam"
            fi
            echo "â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›"
          fi

      - name: Exportar resultados de testes
        uses: actions/upload-artifact@v4
        with:
          name: unit-test-results
          path: |
            TestResults/**/*.trx
            TestResults/**/*.xml
            TestResults/coverage.xml
          if-no-files-found: warn

  # ======================================================
  # 3ï¸âƒ£ INTEGRATION TESTS (CORRIGIDO COM POSTMAN CLI)
  # ======================================================
  integration_tests:
    runs-on: ubuntu-latest
    needs: build

    services:
      postgres:
        image: postgres:16
        env:
          POSTGRES_USER: seepaw
          POSTGRES_PASSWORD: seepaw
          POSTGRES_DB: seepaw_test
        ports:
          - 5432:5432
        options: >-
          --health-cmd="pg_isready -U seepaw -d seepaw_test"
          --health-interval=5s
          --health-timeout=5s
          --health-retries=20

    env:
      ASPNETCORE_ENVIRONMENT: Docker
      ConnectionStrings__DefaultConnection: "Host=localhost;Port=5432;Database=seepaw_test;Username=seepaw;Password=seepaw"

    steps:
      - name: Checkout cÃ³digo
        uses: actions/checkout@v4
        
      - name: Descarregar artefactos do build
        uses: actions/download-artifact@v4
        with:
          name: build-artifacts
          path: ./

      - name: Setup .NET
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: 8.0.x

      - name: Restaurar dependÃªncias
        run: dotnet restore SeePaw.sln

      - name: Compilar projeto
        run: dotnet build SeePaw.sln --no-restore --configuration Release

      - name: Iniciar API em background
        run: |
          echo "ğŸš€ A iniciar a API..."
          dotnet run --project API/API.csproj --configuration Release --no-build --urls "http://0.0.0.0:5000" &
          echo $! > server_pid.txt
          echo "â³ A aguardar que a API fique pronta..."
          timeout 60 bash -c '
             until nc -z localhost 5000; do
              echo "Aguardando..."
              sleep 3
          done
          ' || (echo "âŒ A API nÃ£o respondeu a tempo" && exit 1)
          echo "âœ… API pronta!"

      - name: Instalar Postman CLI
        run: |
          echo "ğŸ“¦ A instalar Postman CLI..."
          curl -o- "https://dl-cli.pstmn.io/install/linux64.sh" | sh

      - name: Login no Postman CLI
        run: postman login --with-api-key ${{ secrets.POSTMAN_API_KEY }}

      - name: Executar testes Postman e gerar relatÃ³rios
        run: |
          set -e
          
          mkdir -p TestResults/postman
          
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“"
          echo "ğŸ§ª TESTES DE INTEGRAÃ‡ÃƒO - POSTMAN"
          echo "â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›"
          echo ""
          
          # Executar a coleÃ§Ã£o "Tests" usando o Postman CLI
          # NOTA: Postman CLI suporta apenas: cli, json, junit, html (bÃ¡sico)
          postman collection run "${{ secrets.POSTMAN_COLLECTION_ID }}" \
            -e "${{ secrets.POSTMAN_ENV_ID }}" \
            --env-var "url=http://localhost:5000" \
            --reporters cli,json,html \
            --reporter-json-export TestResults/postman/results.json \
            --reporter-html-export TestResults/postman/report.html \
            --delay-request 300 \
            --timeout-request 10000 \
            --bail false \
            --color on \
            2>&1 | tee TestResults/postman/console-output.txt
          
          exit_code=${PIPESTATUS[0]}
          
          echo ""
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          
          # Processar resultados
          if [ -f TestResults/postman/results.json ]; then
            total=$(jq -r '.run.stats.assertions.total // 0' TestResults/postman/results.json)
            failed=$(jq -r '.run.stats.assertions.failed // 0' TestResults/postman/results.json)
            passed=$((total - failed))
            
            echo "ğŸ“Š RESUMO DOS TESTES:"
            echo "   Total: $total"
            echo "   âœ… Passaram: $passed"
            echo "   âŒ Falharam: $failed"
            
            if [ $failed -gt 0 ]; then
              echo ""
              echo "âš ï¸  Alguns testes falharam!"
              echo "ğŸ“„ Consulta o relatÃ³rio HTML para mais detalhes"
            else
              echo ""
              echo "ğŸ‰ Todos os testes passaram!"
            fi
            
            # Criar resumo em JSON
            cat > TestResults/postman/summary.json <<EOF
          {
            "total": $total,
            "passed": $passed,
            "failed": $failed,
            "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
            "status": $([ $failed -eq 0 ] && echo '"PASS"' || echo '"FAIL"')
          }
          EOF
          else
            echo "âŒ Erro: Ficheiro de resultados nÃ£o foi gerado"
            exit 1
          fi
          
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          
          # Retornar o exit code original do Postman CLI
          exit $exit_code

      - name: Upload resultados de integraÃ§Ã£o
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: integration-test-results
          path: |
            TestResults/postman/**
          if-no-files-found: warn

      - name: Publicar relatÃ³rio HTML como comentÃ¡rio no PR
        if: always() && github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            
            let summary = { total: 0, passed: 0, failed: 0, status: 'UNKNOWN' };
            
            try {
              const summaryFile = 'TestResults/postman/summary.json';
              if (fs.existsSync(summaryFile)) {
                summary = JSON.parse(fs.readFileSync(summaryFile, 'utf8'));
              }
            } catch (error) {
              console.error('Erro ao ler resumo:', error);
            }
            
            const emoji = summary.status === 'PASS' ? 'âœ…' : 'âŒ';
            const statusText = summary.status === 'PASS' ? 'PASSOU' : 'FALHOU';
            
            const comment = `
            ## ${emoji} Testes de IntegraÃ§Ã£o (Postman) - ${statusText}
            
            **Resumo:**
            - ğŸ§ª Total de testes: ${summary.total}
            - âœ… Passaram: ${summary.passed}
            - âŒ Falharam: ${summary.failed}
            
            ğŸ“„ **RelatÃ³rio HTML completo disponÃ­vel nos artefactos desta execuÃ§Ã£o.**
            
            Para visualizar o relatÃ³rio detalhado:
            1. Vai aos artefactos desta workflow run
            2. Descarrega \`integration-test-results\`
            3. Abre o ficheiro \`report.html\` no browser
            `;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });

      - name: Parar API e containers
        if: always()
        run: |
          echo "ğŸ§¹ A encerrar ambiente de teste..."
          kill $(cat server_pid.txt) || true

  # ======================================================
  # 4ï¸âƒ£ QUALITY GATE (SonarCloud)
  # ======================================================
  quality_gate:
    runs-on: ubuntu-latest
    needs: [unit_tests, integration_tests]

    steps:
      - name: Checkout cÃ³digo
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Download resultados de testes
        uses: actions/download-artifact@v4
        with:
          name: integration-test-results
          path: TestResults/integration/
          
      - name: Download resultados de testes
        uses: actions/download-artifact@v4
        with:
          name: unit-test-results
          path: TestResults/unit/

      - name: Debug - Listar artefactos recebidos
        run: |
          echo "ğŸ“‚ ConteÃºdo de TestResults/unit:"
          ls -lah TestResults/unit/ || echo "Pasta nÃ£o existe"
          echo ""
          echo "ğŸ“‚ ConteÃºdo de TestResults/integration:"
          ls -lah TestResults/integration/ || echo "Pasta nÃ£o existe"
          echo ""
          echo "ğŸ” Procurando ficheiros XML recursivamente:"
          find TestResults -type f -name "*.xml" || echo "Nenhum XML encontrado"
          echo ""
          echo "ğŸ” Procurando ficheiros TRX recursivamente:"
          find TestResults -type f -name "*.trx" || echo "Nenhum TRX encontrado"
          
      - name: Validar existÃªncia dos artefactos
        run: |
          echo "ğŸ” Verificando artefactos..."

          if [ ! -d TestResults/unit ]; then
            echo "âŒ Pasta TestResults/unit nÃ£o encontrada"
            exit 1
          fi
          
          if [ ! -d TestResults/integration ]; then
            echo "âŒ Pasta TestResults/integration nÃ£o encontrada"
            exit 1
          fi
          
          if ! find TestResults/unit -name "*.trx" -type f | grep -q .; then
            echo "âŒ Ficheiro .trx de testes unitÃ¡rios nÃ£o encontrado"
            exit 1
          fi
          
          if ! find TestResults/unit -name "*.xml" -type f | grep -q .; then
            echo "âŒ Ficheiro XML de cobertura nÃ£o encontrado"
            echo "ğŸ” Estrutura de TestResults/unit:"
            find TestResults/unit -type f
            exit 1
          fi
          
          echo "âœ… Todos os artefactos encontrados"

      - name: Quality Gate 1 - Validar Testes UnitÃ¡rios
        run: |
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“"
          echo "ğŸ“Š QUALITY GATE 1: TESTES UNITÃRIOS"
          echo "â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›"
          
          trx_file=$(find TestResults/unit -name "*.trx" | head -1)
          
          if [ -z "$trx_file" ]; then
            echo "âŒ Ficheiro TRX nÃ£o encontrado"
            exit 1
          fi
          
          passed=$(grep -o 'outcome="Passed"' "$trx_file" | wc -l || echo "0")
          failed=$(grep -o 'outcome="Failed"' "$trx_file" | wc -l || echo "0")
          total=$((passed + failed))
          
          echo "Total de testes: $total"
          echo "âœ… Passaram: $passed"
          echo "âŒ Falharam: $failed"
          
          if [ $failed -gt 0 ]; then
            echo ""
            echo "âŒ QUALITY GATE FALHOU: $failed teste(s) unitÃ¡rio(s) falharam"
            exit 1
          fi
          
          if [ $total -eq 0 ]; then
            echo ""
            echo "âŒ QUALITY GATE FALHOU: Nenhum teste unitÃ¡rio foi executado"
            exit 1
          fi
          
          echo ""
          echo "âœ… QUALITY GATE PASSOU: Todos os $total testes unitÃ¡rios passaram"

      - name: Quality Gate 2 - Validar Testes de IntegraÃ§Ã£o (Postman)
        run: |
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“"
          echo "ğŸ“Š QUALITY GATE 2: TESTES DE INTEGRAÃ‡ÃƒO"
          echo "â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›"
          
          summary_file="TestResults/integration/postman/summary.json"
          
          if [ ! -f "$summary_file" ]; then
            echo "âš ï¸ Ficheiro summary.json nÃ£o encontrado"
            echo "â„¹ï¸ QUALITY GATE PASSOU: Nenhum teste de integraÃ§Ã£o configurado"
            exit 0
          fi
          
          if ! command -v jq &> /dev/null; then
            sudo apt-get update -qq
            sudo apt-get install -y jq
          fi
          
          total=$(jq -r '.total // 0' "$summary_file")
          passed=$(jq -r '.passed // 0' "$summary_file")
          failed=$(jq -r '.failed // 0' "$summary_file")
          
          echo "Total de testes: $total"
          echo "âœ… Passaram: $passed"
          echo "âŒ Falharam: $failed"
          
          if [ $failed -gt 0 ]; then
            echo ""
            echo "âŒ QUALITY GATE FALHOU: $failed teste(s) de integraÃ§Ã£o falharam"
            exit 1
          fi
          
          if [ $total -eq 0 ]; then
            echo ""
            echo "â„¹ï¸ QUALITY GATE PASSOU: Nenhum teste de integraÃ§Ã£o foi executado"
            exit 0
          fi
          
          echo ""
          echo "âœ… QUALITY GATE PASSOU: Todos os $total testes de integraÃ§Ã£o passaram"
          
      - name: Restaurar dependÃªncias
        run: dotnet restore SeePaw.sln
  
      - name: Build do projeto
        run: dotnet build SeePaw.sln --no-restore --configuration Release
      

      - name: Enviar cobertura para Codacy
        run: |
          echo "ğŸ“¤ Enviando relatÃ³rio de cobertura para Codacy..."
          export CODACY_PROJECT_TOKEN="${{ secrets.CODACY_PROJECT_TOKEN }}"
          
          if [ -z "$CODACY_PROJECT_TOKEN" ]; then
            echo "âŒ Erro: CODACY_PROJECT_TOKEN nÃ£o configurado"
            exit 1
          fi
          curl -Ls https://coverage.codacy.com/get.sh -o codacy-coverage-reporter.sh
          chmod +x codacy-coverage-reporter.sh

          ./codacy-coverage-reporter.sh report \
            -r TestResults/unit/coverage.xml \
            --commit-uuid ${{ github.sha }} \
            --partial || echo "âš ï¸ Envio parcial ou falhou (nÃ£o crÃ­tico)"
          echo "âœ… Tentativa de envio concluÃ­da"
    
      - name: Quality Gate 3 - Verificar Codacy Quality Gate
        run: |
          echo "â³ Aguardando que o Codacy analise o commit..."
          COMMIT_SHA="${{ github.sha }}"
          TOKEN="${{ secrets.CODACY_TOKEN }}"
          MAX_RETRIES=15   # tenta atÃ© 15 vezes
          DELAY=60         # 60 segundos entre tentativas

          if [ -z "$TOKEN" ]; then
            echo "âŒ CODACY_TOKEN nÃ£o configurado!"
            exit 1
          fi
          for ((i=1; i<=MAX_RETRIES; i++)); do
            response=$(curl -s -w "\n%{http_code}" \
              "https://app.codacy.com/api/v3/analysis/organizations/gh/see-paw/repositories/backend/commits/$COMMIT_SHA" \
              -H "api-token: $TOKEN")
            
            http_code=$(echo "$response" | tail -n1)
            body=$(echo "$response" | head -n-1)

            if [ "$http_code" = "200" ]; then
              echo "âœ… Commit analisado pelo Codacy!"
              echo "$body" | jq '.' > codacy_commit.json
              break
            else
              echo "ğŸ”„ [$i/$MAX_RETRIES] Ainda nÃ£o analisado... (HTTP $http_code)"
              sleep $DELAY
            fi
          done

          if [ "$http_code" != "200" ]; then
            echo "âŒ Timeout: Codacy nÃ£o terminou a anÃ¡lise apÃ³s $((MAX_RETRIES*DELAY/60)) min"
            exit 1
          fi
          echo "âœ… Dados gravados em codacy_commit.json"
    
      - name: Quality Gate 4 - Validar MÃ©tricas Personalizadas (SeePaw)
        run: |
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“"
          echo "ğŸ“Š QUALITY GATE 4: MÃ‰TRICAS PERSONALIZADAS SEEPAW"
          echo "â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›"
          
          COMMIT_SHA="${{ github.sha }}"
          TOKEN_TYPE="${CODACY_TOKEN_TYPE:-api-token}"
          VALID_TOKEN="${CODACY_VALID_TOKEN}"
          
          # Se nÃ£o tiver token vÃ¡lido do step anterior, tentar descobrir
          if [ -z "$VALID_TOKEN" ]; then
            if [ -n "${{ secrets.CODACY_API_TOKEN }}" ]; then
              response=$(curl -s -w "\n%{http_code}" \
                "https://app.codacy.com/api/v3/analysis/organizations/gh/see-paw/repositories/backend/commits/$COMMIT_SHA" \
                -H "api-token: ${{ secrets.CODACY_API_TOKEN }}")
              
              http_code=$(echo "$response" | tail -n1)
              if [ "$http_code" = "200" ]; then
                VALID_TOKEN="${{ secrets.CODACY_API_TOKEN }}"
                TOKEN_TYPE="api-token"
              fi
            fi
            
            if [ -z "$VALID_TOKEN" ] && [ -n "${{ secrets.CODACY_TOKEN }}" ]; then
              response=$(curl -s -w "\n%{http_code}" \
                "https://app.codacy.com/api/v3/analysis/organizations/gh/see-paw/repositories/backend/commits/$COMMIT_SHA" \
                -H "api-token: ${{ secrets.CODACY_TOKEN }}")
              
              http_code=$(echo "$response" | tail -n1)
              if [ "$http_code" = "200" ]; then
                VALID_TOKEN="${{ secrets.CODACY_TOKEN }}"
                TOKEN_TYPE="api-token"
              fi
            fi
          fi
          
          if [ -z "$VALID_TOKEN" ]; then
            echo "âŒ Erro: Nenhum token vÃ¡lido encontrado"
            exit 1
          fi
          
          # Obter mÃ©tricas do Codacy
          response=$(curl -s -w "\n%{http_code}" \
            "https://app.codacy.com/api/v3/analysis/organizations/gh/see-paw/repositories/backend/commits/$COMMIT_SHA" \
            -H "$TOKEN_TYPE: $VALID_TOKEN")
          
          http_code=$(echo "$response" | tail -n1)
          body=$(echo "$response" | head -n-1)
          
          echo "ğŸ” Debug - Response do Codacy (HTTP $http_code):"
          echo "$body" | jq '.' 2>/dev/null || echo "$body"
          echo ""
          
          if [ "$http_code" != "200" ]; then
            echo "âŒ Erro ao consultar API do Codacy"
            exit 1
          fi
          
          # Extrair mÃ©tricas
          coverage=$(echo "$body" | jq -r '.data.coverage.coveragePercentage // 0' | cut -d'.' -f1)
          complexity=$(echo "$body" | jq -r '.data.complexity.value // 0' | cut -d'.' -f1)
          issues=$(echo "$body" | jq -r '.data.issues.total // 0')
          
          # Obter detalhes das issues por categoria
          issues_response=$(curl -s -w "\n%{http_code}" \
            "https://app.codacy.com/api/v3/analysis/organizations/gh/see-paw/repositories/backend/issues?commit=$COMMIT_SHA&limit=1000" \
            -H "$TOKEN_TYPE: $VALID_TOKEN")
          
          issues_http_code=$(echo "$issues_response" | tail -n1)
          issues_body=$(echo "$issues_response" | head -n-1)
          
          if [ "$issues_http_code" = "200" ]; then
            bugs=$(echo "$issues_body" | jq '[.data[] | select(.category=="Error Prone")] | length')
            vulnerabilities=$(echo "$issues_body" | jq '[.data[] | select(.category=="Security")] | length')
            smells=$(echo "$issues_body" | jq '[.data[] | select(.category=="Code Style")] | length')
            
            # Se nÃ£o conseguir categorizar, tentar outros nomes de categorias
            if [ "$bugs" = "0" ] && [ "$vulnerabilities" = "0" ] && [ "$smells" = "0" ] && [ "$issues" -gt 0 ]; then
              echo "âš ï¸ Tentando categorias alternativas..."
              bugs=$(echo "$issues_body" | jq '[.data[] | select(.level=="Error")] | length')
              vulnerabilities=$(echo "$issues_body" | jq '[.data[] | select(.level=="Warning" and (.category | contains("Security")))] | length')
              smells=$(echo "$issues_body" | jq '[.data[] | select(.level=="Info" or .level=="Warning")] | length')
            fi
          else
            echo "âš ï¸ NÃ£o foi possÃ­vel obter detalhes das issues (HTTP $issues_http_code)"
            bugs=0
            vulnerabilities=0
            smells=$issues
          fi
          
          # Garantir valores numÃ©ricos
          if [ "$bugs" = "null" ] || [ -z "$bugs" ]; then bugs=0; fi
          if [ "$vulnerabilities" = "null" ] || [ -z "$vulnerabilities" ]; then vulnerabilities=0; fi
          if [ "$smells" = "null" ] || [ -z "$smells" ]; then smells=$issues; fi
          
          pr_title="${{ github.event.pull_request.title || 'Basic' }}"
          
          category="Basic"
          min_coverage=40
          
          if echo "$pr_title" | grep -iq "intermediate"; then
            category="Intermediate"
            min_coverage=50
          elif echo "$pr_title" | grep -iq "critical"; then
            category="Critical"
            min_coverage=80
          fi
          
          echo "ğŸ“‹ Categoria detectada: $category"
          echo "ğŸ“Š Cobertura mÃ­nima requerida: ${min_coverage}%"
          echo ""
          echo "ğŸ“ˆ MÃ©tricas obtidas:"
          echo "   Cobertura de cÃ³digo: ${coverage}%"
          echo "   Complexidade ciclomÃ¡tica: $complexity"
          echo "   Code Smells: $smells"
          echo "   Bugs: $bugs"
          echo "   Vulnerabilidades: $vulnerabilities"
          echo "   Total de issues: $issues"
          echo ""
          
          failed=0
          
          echo "ğŸ” Validando mÃ©tricas..."
          
          if [ "$coverage" -lt "$min_coverage" ]; then
            echo "   âŒ Cobertura: ${coverage}% < ${min_coverage}% (mÃ­nimo para $category)"
            failed=1
          else
            echo "   âœ… Cobertura: ${coverage}% >= ${min_coverage}%"
          fi
          
          if [ "$complexity" -gt 14 ]; then
            echo "   âŒ Complexidade: $complexity > 14 (mÃ¡ximo)"
            failed=1
          else
            echo "   âœ… Complexidade: $complexity <= 14"
          fi
          
          if [ "$bugs" -gt 0 ]; then
            echo "   âŒ Bugs: $bugs > 0 (mÃ¡ximo)"
            failed=1
          else
            echo "   âœ… Bugs: $bugs = 0"
          fi
          
          if [ "$vulnerabilities" -gt 0 ]; then
            echo "   âŒ Vulnerabilidades: $vulnerabilities > 0 (mÃ¡ximo)"
            failed=1
          else
            echo "   âœ… Vulnerabilidades: $vulnerabilities = 0"
          fi
          
          if [ "$smells" -gt 10 ]; then
            echo "   âŒ Code Smells: $smells > 10 (mÃ¡ximo)"
            failed=1
          else
            echo "   âœ… Code Smells: $smells <= 10"
          fi
          
          jq -n \
            --arg coverage "$coverage" \
            --arg complexity "$complexity" \
            --arg smells "$smells" \
            --arg bugs "$bugs" \
            --arg vulnerabilities "$vulnerabilities" \
            --arg category "$category" \
            --arg min_cov "$min_coverage" \
            '{
              coverage: $coverage,
              complexity: $complexity,
              code_smells: $smells,
              bugs: $bugs,
              vulnerabilities: $vulnerabilities,
              category: $category,
              min_coverage: $min_cov,
              timestamp: (now | todate)
            }' > metrics.json
          
          echo ""
          if [ $failed -eq 1 ]; then
            echo "âŒ QUALITY GATE FALHOU: MÃ©tricas personalizadas nÃ£o atingidas"
            exit 1
          else
            echo "âœ… QUALITY GATE PASSOU: Todas as mÃ©tricas personalizadas atingidas"
          fi

      - name: Resumo Final dos Quality Gates
        if: always()
        run: |
          echo ""
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“"
          echo "ğŸ¯ RESUMO DOS QUALITY GATES"
          echo "â”£â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”«"
          echo "âœ… Quality Gate 1: Testes UnitÃ¡rios"
          echo "âœ… Quality Gate 2: Testes de IntegraÃ§Ã£o"
          echo "âœ… Quality Gate 3: SonarCloud"
          echo "âœ… Quality Gate 4: MÃ©tricas Personalizadas"
          echo "â”£â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”«"
          echo "ğŸ‰ TODOS OS QUALITY GATES PASSARAM!"
          echo "â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›"
  
      - name: Guardar artefacto das mÃ©tricas
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: quality-metrics
          path: metrics.json
